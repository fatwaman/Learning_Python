{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "we9N6WDjnCBI",
        "FqwZzjXxMxSY",
        "BMY16Vo3LpbY",
        "NjeWMYrPNxhi",
        "26reEOSgOI0k",
        "MnipyEtBcrJz",
        "z6uN2O8zc2Vc",
        "SCHvHEIGaSBX",
        "xwMAUVLwaqID",
        "QyE48poHbYKY"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZVM7QaY2PFmLkqhETBp8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatwaman/Learning_Python/blob/main/Capstone_Project_Fatwa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load Libraries and Dataset**"
      ],
      "metadata": {
        "id": "NDD2BuC-E9fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1. Import Necessary Libraries and Dataset"
      ],
      "metadata": {
        "id": "TxxczM5PHv3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re #regex\n",
        "\n",
        "# Import dataset which still in sql file (MySQL)\n",
        "from google.colab import files\n",
        "upload = files.upload()\n",
        "file_path = 'datatransaksi.sql'"
      ],
      "metadata": {
        "id": "EPbCCXXqE70m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1.1 Convert Dataset to JSON format"
      ],
      "metadata": {
        "id": "we9N6WDjnCBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_mysql_insert(file_path):\n",
        "    \"\"\"\n",
        "    Parses a MySQL .sql file, extracts data from INSERT statements, and returns a list of dictionaries.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    # Regex to find the values inside the `values(...)` part of an INSERT statement\n",
        "    pattern = re.compile(r\"values\\((.*?)\\);\")\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            # Check for INSERT statements\n",
        "            if line.startswith(\"insert into `laporan`\"):\n",
        "                match = pattern.search(line)\n",
        "                if match:\n",
        "                    values_string = match.group(1)\n",
        "                    # Split the string by single quotes and commas to get individual values\n",
        "                    # The regex splits by a comma followed by a single quote, which is more robust\n",
        "                    # than a simple comma split for cases where values might contain commas.\n",
        "                    values = re.findall(r\"'([^']*)'\", values_string)\n",
        "\n",
        "                    # Convert values to the correct data types based on the table schema\n",
        "                    # id: int, id_user: int, tanggal: varchar, jumlah_transaksi: int, jumlah_total: float\n",
        "                    record = {\n",
        "                        \"id\": int(values[0]),\n",
        "                        \"id_user\": int(values[1]),\n",
        "                        \"tanggal\": values[2],\n",
        "                        \"jumlah_transaksi\": int(values[3]),\n",
        "                        \"jumlah_total\": float(values[4])\n",
        "                    }\n",
        "                    data.append(record)\n",
        "    return data\n",
        "\n",
        "# Replace 'datatransaksi.sql' with the actual path to your file\n",
        "parsed_data = parse_mysql_insert(file_path)\n",
        "\n",
        "# Print the parsed data\n",
        "import json\n",
        "print(json.dumps(parsed_data[:5], indent=4)) # Print Top 5 JSON Result\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xX4OZ649nLSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1.2 Convert JSON Parsing to Pandas Dataframe"
      ],
      "metadata": {
        "id": "FqwZzjXxMxSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts it into a pandas DataFrame. Table-like structure similar to a spreadsheet or a table in a database\n",
        "df = pd.DataFrame(parsed_data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qGFkakYyMtkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Cleaning**"
      ],
      "metadata": {
        "id": "ZU4J5ot2PW5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Rename Column and Check Important Column"
      ],
      "metadata": {
        "id": "BMY16Vo3LpbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column standardization and date parsing\n",
        "\n",
        "# Read as a string so that date parsing can be controlled\n",
        "df = pd.DataFrame(parsed_data)\n",
        "\n",
        "# Rename column name to english version\n",
        "rename_map = {\n",
        "    'tanggal': 'date',\n",
        "    'jumlah_transaksi': 'number of transactions',\n",
        "    'jumlah_total': 'total_amount'\n",
        "}\n",
        "df.rename(columns = rename_map, inplace = True)\n",
        "#df = df.rename(columns={c:e for c,e in rename_map.items() if c in df.columns})\n",
        "\n",
        "# Check important columns and raise error if found\n",
        "required = {'id_user', 'date', 'total_amount'}\n",
        "missing = required - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Required column is missing: {missing}. Please check your sql file.\")"
      ],
      "metadata": {
        "id": "DP0eQqYj8Vwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Tidy Up Column Name"
      ],
      "metadata": {
        "id": "NjeWMYrPNxhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tidy up column name (trim the name and make all lowercase)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Check id_user columnn and convert to string\n",
        "df['id_user'] = df['id_user'].astype(str).str.strip()\n",
        "\n",
        "# Check total_amount columnn and convert to numeric\n",
        "df['total_amount'] = pd.to_numeric(df['total_amount'], errors='coerce')"
      ],
      "metadata": {
        "id": "Pa9xhEBRNwBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 Date Cleaning and Standardization"
      ],
      "metadata": {
        "id": "26reEOSgOI0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing date ensures all its values are treated as strings and trim the value\n",
        "s = df['date'].astype(str).str.strip()\n",
        "\n",
        "# Change date separator from \".\" or \"/\" to \"-\"\n",
        "s = s.str.replace(r'[./]', '-', regex=True)\n",
        "\n",
        "# Check common date pattern\n",
        "mask_ymd   = s.str.match(r'^\\d{4}-\\d{1,2}-\\d{1,2}$')   # YYYY-MM-DD\n",
        "mask_dmy   = s.str.match(r'^\\d{1,2}-\\d{1,2}-\\d{4}$')   # DD-MM-YYYY\n",
        "mask_8dig  = s.str.match(r'^\\d{8}$')                   # YYYYMMDD\n",
        "\n",
        "date_nya = pd.Series(pd.NaT, index=s.index, dtype='datetime64[ns]')\n",
        "date_nya[mask_ymd]  = pd.to_datetime(s[mask_ymd],  format='%Y-%m-%d', errors='coerce')\n",
        "date_nya[mask_dmy]  = pd.to_datetime(s[mask_dmy],  format='%d-%m-%Y', errors='coerce')\n",
        "date_nya[mask_8dig] = pd.to_datetime(s[mask_8dig], format='%Y%m%d',   errors='coerce')\n",
        "rest = ~(mask_ymd | mask_dmy | mask_8dig)\n",
        "date_nya[rest] = pd.to_datetime(s[rest], errors='coerce', dayfirst=True)\n",
        "\n",
        "df['date'] = date_nya\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SfHOBOscOOwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Implement Large Language Model (LLM)**"
      ],
      "metadata": {
        "id": "Q43_YWEfCORY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Install LLM from Replicate (replicate.com)"
      ],
      "metadata": {
        "id": "MnipyEtBcrJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install llm\n",
        "!pip install replicate\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zYP6qXChCXQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Set Up API Token and Model Environment"
      ],
      "metadata": {
        "id": "z6uN2O8zc2Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set the API token\n",
        "api_token = userdata.get(\"api_token\")\n",
        "os.environ['REPLICATE_API_TOKEN'] = api_token\n",
        "\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "llm = Replicate(\n",
        "    model=model,\n",
        "    replicate_api_token=api_token,\n",
        ")"
      ],
      "metadata": {
        "id": "cSqI1KYzC_IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 Give Order to LLM and Try the Result"
      ],
      "metadata": {
        "id": "iFWTI_KDdOay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"in what date which have highest total_amount from datatransksi? please make python script\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "K8yAgqFQltPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a641bd05"
      },
      "source": [
        "max_amount_row = df.sort_values('total_amount', ascending=False).iloc[0]\n",
        "print(\"Date with the highest total_amount:\", max_amount_row.name)\n",
        "\n",
        "# highest_date = df.loc[df['total_amount'].idxmax(), 'date']\n",
        "# highest_amount = df['total_amount'].max()\n",
        "\n",
        "# print(f\"The date with the highest total_amount is {highest_date} with an amount of {highest_amount}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"I want to see trend line chart of total_amount in yearly basis, please make python script\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "CDLSmQ8e63kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['year'] = pd.to_datetime(df['date'], format='%Y')\n",
        "\n",
        "# Set 'year' as the index\n",
        "df.set_index('year', inplace=True)\n",
        "\n",
        "# Plotting the trend line\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df.index, df['total_amount'], marker='o')\n",
        "plt.title('Total Amount Trend Over Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total Amount')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zSuu4O_0WiK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and 'year' and 'total_amount' are columns\n",
        "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
        "df.set_index('year', inplace=True)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df['total_amount'], label='Total Amount')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total Amount')\n",
        "plt.title('Total Amount Trend Over Years')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-RgYmCvb7KgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"Using the provided datatransaksi, conduct a monthly cohort analysis to determine how long users retain the transaction feature. Ensure that only transactions with total_transactions > 0 are counted.\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "E0YKd9QK7q3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Cohort Preparation**"
      ],
      "metadata": {
        "id": "OB8Dz5qOYyOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Filter Data"
      ],
      "metadata": {
        "id": "vSMJf_93OY5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter valid data which are not NaT (Not a Time) or NoN (Not a Number) and total_amount > 0\n",
        "df = df.dropna(subset=['date', 'id_user', 'total_amount']) # Filter exclude NaT or NaN data\n",
        "df = df[df['total_amount'] > 0] # Filter total_amount > 0\n",
        "\n",
        "# Check if found years anomaly, in this data are take out < 2010\n",
        "yrs = df['date'].dt.year\n",
        "print(\"Date range is from:\", df['date'].min(), \"→\", df['date'].max())\n",
        "print(\"Number of rows which have year < 2010:\", int((yrs < 2010).sum()), \"row(s)\")"
      ],
      "metadata": {
        "id": "nTENdJoIOiYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['date'].dt.year >= 2015].reset_index(drop=True) # Resets the index to a clean sequence starting from 0\n",
        "df[ df['date'].dt.year < 2015 ].head(10) # Quick check to see if any data from before the year 2000 still exists in the DataFrame after the filtering step"
      ],
      "metadata": {
        "id": "r-iz2R4QYrrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Define Transaction Month and Cohort Month"
      ],
      "metadata": {
        "id": "SCHvHEIGaSBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For transaction month and Cohort month, and aging\n",
        "# Bulan transaksi & bulan cohort (gunakan Period → aman)\n",
        "df['transaction_month']  = df['date'].dt.to_period('M').dt.to_timestamp()\n",
        "\n",
        "first_tx = (df.groupby('id_user', as_index=False)['transaction_month']\n",
        "              .min()\n",
        "              .rename(columns={'transaction_month':'cohort_month'}))\n",
        "\n",
        "df = df.merge(first_tx, on='id_user', how='left')\n",
        "\n",
        "def month_diff(d1, d2):\n",
        "    return (d1.dt.year - d2.dt.year) * 12 + (d1.dt.month - d2.dt.month)\n",
        "\n",
        "df['cohort_index'] = month_diff(df['transaction_month'], df['cohort_month']) + 1\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fHITOkiwY8gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 Matrix Retention Calculation and Active User"
      ],
      "metadata": {
        "id": "xwMAUVLwaqID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Retension Matrix (Percentage)\n",
        "# Active user per (cohort_month x cohort_index)\n",
        "cohort_counts = (\n",
        "    df.groupby(['cohort_month', 'cohort_index'])['id_user']\n",
        "      .nunique()\n",
        "      .reset_index(name='active_users')\n",
        ")\n",
        "\n",
        "# Cohort size = user on first month\n",
        "cohort_sizes = (\n",
        "    cohort_counts[cohort_counts['cohort_index'] == 1]\n",
        "    .rename(columns={'active_users':'cohort_size'})[['cohort_month','cohort_size']]\n",
        ")\n",
        "\n",
        "cohort_counts = cohort_counts.merge(cohort_sizes, on='cohort_month', how='left')\n",
        "cohort_counts['retention'] = cohort_counts['active_users'] / cohort_counts['cohort_size']\n",
        "\n",
        "# Pivot → persen\n",
        "retention_pct = (cohort_counts.pivot_table(\n",
        "    index='cohort_month', columns='cohort_index',\n",
        "    values='retention', aggfunc='mean'\n",
        ").fillna(0) * 100).round(1)\n",
        "\n",
        "retention_pct.index = retention_pct.index.strftime('%Y-%m')  # rapi\n",
        "retention_pct.head()\n"
      ],
      "metadata": {
        "id": "Gud86yk2a4bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4 Cohort Visualization"
      ],
      "metadata": {
        "id": "QyE48poHbYKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visuzalization using Heatmap\n",
        "# Limit the Column (optional so it's not too crowded)\n",
        "N = 18  # ubah ke 12/18/24 sesuai kebutuhan\n",
        "plot_df = retention_pct.copy()\n",
        "plot_df = plot_df.loc[:, [c for c in plot_df.columns if c <= N]]\n",
        "\n",
        "# Zero change to NaN to make white background & And zero value is not writen\n",
        "plot_df = plot_df.replace(0, np.nan)\n",
        "\n",
        "# Plot\n",
        "h, w = max(4, 0.4*plot_df.shape[0]+2), max(8, 0.6*plot_df.shape[1]+2)\n",
        "plt.figure(figsize=(w, h))\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    plot_df, cmap=\"YlGnBu\", annot=True, fmt=\".1f\",\n",
        "    linewidths=0.5, linecolor=\"white\",\n",
        "    cbar_kws={\"label\": \"Retention (%)\"},\n",
        "    vmin=0, vmax=100\n",
        ")\n",
        "ax.set_xlabel(\"Month to-n since Cohort\")\n",
        "ax.set_ylabel(\"Cohort (YYYY-MM)\")\n",
        "ax.set_title(\"Cohort Retention Monthly (Transaction > 0)\")\n",
        "ax.tick_params(axis=\"x\", rotation=0)\n",
        "ax.tick_params(axis=\"y\", rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2yYMJt9Cbbim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}